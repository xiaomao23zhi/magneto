image:
  # -- Image repository
  repository: harbor.datamodel.jiutian.hq.cmcc:8089/spark/spark-operator
  # -- Image pull policy
  pullPolicy: IfNotPresent
  # -- Overrides the image tag whose default is the chart appVersion.
  tag: "v1beta2-1.2.3-3.1.1"

rbac:
  # -- **DEPRECATED** use `createRole` and `createClusterRole`
  create: false
  # -- Create and use RBAC `Role` resources
  createRole: true
  # -- Create and use RBAC `ClusterRole` resources
  createClusterRole: true

# -- Set this if running spark jobs in a different namespace than the operator
sparkJobNamespace: "spark"

# -- Operator concurrency, higher values might increase memory usage
controllerThreads: 10

# -- Operator resync interval. Note that the operator will respond to events (e.g. create, update)
# unrelated to this setting
resyncInterval: 30

uiService:
  # -- Enable UI service creation for Spark application
  enable: true

# -- Ingress URL format.
# Requires the UI service to be enabled by setting `uiService.enable` to true.
ingressUrlFormat: "kshjm.cmcc.mobile.cn/{{$appNamespace}}/{{$appName}}"

webhook:
  # -- Enable webhook server
  enable: true


# nodeSelector -- Node labels for pod assignment
nodeSelector:
  node: compute

# resources -- Pod resource requests and limits
# Note, that each job submission will spawn a JVM within the Spark Operator Pod using "/usr/local/openjdk-11/bin/java -Xmx128m".
# Kubernetes may kill these Java processes at will to enforce resource limits. When that happens, you will see the following error:
# 'failed to run spark-submit for SparkApplication [...]: signal: killed' - when this happens, you may want to increase memory limits.
resources: {}
  # limits:
  #   cpu: 100m
  #   memory: 300Mi
  # requests:
  #   cpu: 100m
  #   memory: 300Mi

batchScheduler:
  # -- Enable batch scheduler for spark jobs scheduling. If enabled, users can specify batch scheduler name in spark application
  enable: false

resourceQuotaEnforcement:
  # -- Whether to enable the ResourceQuota enforcement for SparkApplication resources.
  # Requires the webhook to be enabled by setting `webhook.enable` to true.
  # Ref: https://github.com/GoogleCloudPlatform/spark-on-k8s-operator/blob/master/docs/user-guide.md#enabling-resource-quota-enforcement.
  enable: false

leaderElection:
  # -- Leader election lock name.
  # Ref: https://github.com/GoogleCloudPlatform/spark-on-k8s-operator/blob/master/docs/user-guide.md#enabling-leader-election-for-high-availability.
  lockName: "spark-operator-lock"
  # -- Optionally store the lock in another namespace. Defaults to operator's namespace
  lockNamespace: ""

istio:
  # -- When using `istio`, spark jobs need to run without a sidecar to properly terminate
  enabled: false

# labelSelectorFilter -- A comma-separated list of key=value, or key labels to filter resources during watch and list based on the specified labels.
labelSelectorFilter: ""
