image:
  repository: apache/livy
  tag: 0.8.0-incubating-spark_3.2.1_2.12-hadoop_3.2.0_cloud
  pullPolicy: IfNotPresent

rbac:
  create: true

#nodeSelector:
#  node: service

sparkHistory:
  enabled: false
  existingClaim: pvc-spark-history

## Persist data to a persistent volume
persistence:
  enabled: false
  # subPath: ""

  ## If defined, will use the existing PVC and will not create a new one.
  existingClaim: pvc-livy-server

  ## If defined, storageClassName: <storageClass>
  ## If set to "-", storageClassName: "", which disables dynamic provisioning
  ## If undefined (the default) or set to null, no storageClassName spec is
  ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
  ##   GKE, AWS & OpenStack)
  ##
  # storageClass: "-"
  accessMode: ReadWriteOnce
  size: 20Gi
  annotations: {}

env:
  #LIVY_LIVY_UI_BASE1PATH: {value: "/livy"} # eg.: `/livy`
  LIVY_LIVY_SERVER_SESSION_STATE0RETAIN_SEC: {value: "72h"}
  LIVY_LIVY_SERVER_SESSION_MAX0CREATION: {value: "100"}
  LIVY_LIVY_SERVER_RECOVERY_MODE: {value: "off"}
#  LIVY_LIVY_SERVER_RECOVERY_STATE0STORE: {value: "filesystem"}
#  LIVY_LIVY_SERVER_RECOVERY_STATE0STORE_URL: {value: "s3a://livy/store"}
  LIVY_LIVY_RSC_JARS: {value: 'local\:///opt/livy/rsc-jars/livy-thriftserver-session-0.8.0-incubating-SNAPSHOT.jar,local\:///opt/livy/rsc-jars/netty-all-4.1.47.Final.jar,local\:///opt/livy/rsc-jars/asm-5.0.4.jar,local\:///opt/livy/rsc-jars/reflectasm-1.11.3.jar,local\:///opt/livy/rsc-jars/minlog-1.3.0.jar,local\:///opt/livy/rsc-jars/livy-rsc-0.8.0-incubating-SNAPSHOT.jar,local\:///opt/livy/rsc-jars/objenesis-2.5.1.jar,local\:///opt/livy/rsc-jars/livy-api-0.8.0-incubating-SNAPSHOT.jar'}
  LIVY_LIVY_REPL_JARS: {value: 'local\:///opt/livy/repl_2.12-jars/commons-codec-1.9.jar,local\:///opt/livy/repl_2.12-jars/livy-core_2.12-0.8.0-incubating-SNAPSHOT.jar,local\:///opt/livy/repl_2.12-jars/livy-repl_2.12-0.8.0-incubating-SNAPSHOT.jar'}
  LIVY_LIVY_FILE_LOCAL0DIR0WHITELIST: {value: "/opt/spark/python/lib"}
  LIVY_LIVY_REPL_ENABLE0HIVE0CONTEXT: {value: "false"}
  LIVY_SPARK_KUBERNETES_CONTAINER_IMAGE: {value: "apache/livy-spark:0.8.0-incubating-spark_3.2.1_2.12-hadoop_3.2.0_cloud"}
  LIVY_SPARK_KUBERNETES_CONTAINER_IMAGE_PULL1POLICY: {value: "IfNotPresent"}
  LIVY_SPARK_EVENT1LOG_ENABLED: {value: "true"}
  LIVY_SPARK_EVENT1LOG_DIR: {value: "s3a://spark/eventLog"}
  LIVY_SPARK_KUBERNETES_DRIVER_ANNOTATION_CREATED0BY: {value: "livy"}
  LIVY_SPARK_KUBERNETES_EXECUTOR_ANNOTATION_CREATED0BY: {value: "livy"}
  LIVY_SPARK_KUBERNETES_DRIVER_LABEL_NAME: {value: "driver"}
  LIVY_SPARK_KUBERNETES_EXECUTOR_LABEL_NAME: {value: "executor"}
#  LIVY_SPARK_KUBERNETES_DRIVER_VOLUMES_PERSISTENT1VOLUME1CLAIM_HISTORY_OPTIONS_CLAIM1NAME: {value: "pvc-spark-history"}
#  LIVY_SPARK_KUBERNETES_DRIVER_VOLUMES_PERSISTENT1VOLUME1CLAIM_HISTORY_MOUNT_PATH: {value: "/opt/spark/history"}
#  LIVY_SPARK_KUBERNETES_EXECUTOR_VOLUMES_PERSISTENT1VOLUME1CLAIM_HISTORY_OPTIONS_CLAIM1NAME: {value: "glusterfs-spark-pvc"}
#  LIVY_SPARK_KUBERNETES_EXECUTOR_VOLUMES_PERSISTENT1VOLUME1CLAIM_HISTORY_MOUNT_PATH: {value: "/data/k8sUpload"}
  LIVY_SPARK_SUBMIT_PY1FILES: {value: "local:///opt/spark/python/lib/pyspark.zip,local:///opt/spark/python/lib/py4j-0.10.9-src.zip"}
  LIVY_SPARK_KUBERNETES_FILE_UPLOAD_PATH: {value: "s3a//spark/upload"}
  # LIVY_SPARK_KUBERNETES_CONTAINER_IMAGE_PULL1SECRETS: {value: ""}
  # LIVY_LIVY_UI_HISTORY1SERVER1URL: {value: "https://cluster.example.com/history-server"} # to build links on Livy UI properly
  #
  # Spark UI proxy configs
  # LIVY_LIVY_SERVER_KUBERNETES_INGRESS_CREATE: {value: "false"}
  # LIVY_LIVY_SERVER_KUBERNETES_INGRESS_HOST: {value: "cluster.example.com"}
  #
  # Authentication configs for Spark UI proxy
  # External auth with OAuth2
  # LIVY_LIVY_SERVER_KUBERNETES_INGRESS_ADDITIONAL1ANNOTATIONS: {value: "kubernetes.io/tls-acme=true;nginx.ingress.kubernetes.io/auth-url=https://$host/oauth2/auth;nginx.ingress.kubernetes.io/auth-signin=https://$host/oauth2/start?rd=$escaped_request_uri"}
  # Basic auth
  # LIVY_LIVY_SERVER_KUBERNETES_INGRESS_ADDITIONAL1ANNOTATIONS: {value: "kubernetes.io/tls-acme=true;nginx.ingress.kubernetes.io/auth-type=basic;nginx.ingress.kubernetes.io/auth-secret=secret-namespace/auth-secret;nginx.ingress.kubernetes.io/auth-realm=Authentication Required"}
  #
  # HTTPS for Spark UI proxy
  # LIVY_LIVY_SERVER_KUBERNETES_INGRESS_PROTOCOL: {value: "https"}
  # LIVY_LIVY_SERVER_KUBERNETES_INGRESS_TLS_SECRET1NAME: {value: "spark-cluster-tls"}
  #
  # Additional Nginx Ingress configs for Spark UI proxy
  # LIVY_LIVY_SERVER_KUBERNETES_INGRESS_ADDITIONAL1CONF1SNIPPET: {value: ""}
  #
  # LIVY_ENV_VAR_FROM_CONFIG_MAP:
  #   valueFrom:
  #     configMapKeyRef:
  #       name: myconfig
  #       key: config.key
  # LIVY_ENV_VAR_FROM_SECRET:
  #   valueFrom:
  #     secretKeyRef:
  #       name: mysecret
  #       key: secret.key

envFrom: []
# - configMapRef:
#     name: env-configmap
# - secretRef:
#     name: env-secrets

livyConf: {}
#  fromConfigMap: "livy-conf-config-map"
#  fromSecret: "livy-conf-secret"

sparkDefaultsConf:
  spark.hadoop.fs.s3a.endpoint: "http://minio.storage.svc:9000"
  spark.hadoop.fs.s3a.access.key: "a3e7d88d4fa8"
  spark.hadoop.fs.s3a.secret.key: "8b622eb12ff7"
  spark.hadoop.fs.s3a.fast.upload: "true"
  spark.hadoop.fs.s3a.path.style.access: "true"
  spark.hadoop.fs.s3a.impl: "org.apache.hadoop.fs.s3a.S3AFileSystem"
# fromConfigMap: "spark-defaults-conf-map"
# fromSecret: "spark-defaults-conf-secret"

livyClientConf: {}
# fromConfigMap: "livy-client-conf-config-map"
# fromSecret: "livy-client-conf-secret"
