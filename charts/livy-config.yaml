image:
  repository: magnote.pub/livy
  tag: 0.8.0-incubating-spark_3.1.1_2.12-hadoop_3.2.0_cloud_TT7
  pullPolicy: IfNotPresent

rbac:
  create: true

nodeSelector:
  node: service

## Persist data to a persistent volume
persistence:
  enabled: true
  # subPath: ""

  ## If defined, will use the existing PVC and will not create a new one.
  existingClaim: glusterfs-spark-pvc

  ## If defined, storageClassName: <storageClass>
  ## If set to "-", storageClassName: "", which disables dynamic provisioning
  ## If undefined (the default) or set to null, no storageClassName spec is
  ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
  ##   GKE, AWS & OpenStack)
  ##
  # storageClass: "-"
  accessMode: ReadWriteOnce
  size: 20Gi
  annotations: {}

env:
  LIVY_LIVY_UI_BASE1PATH: {value: "/livy"} # eg.: `/livy`
  LIVY_LIVY_SERVER_SESSION_STATE0RETAIN_SEC: {value: "72h"}
  LIVY_LIVY_SERVER_SESSION_MAX0CREATION: {value: "100"}
  LIVY_LIVY_SERVER_RECOVERY_MODE: {value: "recovery"}
  LIVY_LIVY_SERVER_RECOVERY_STATE0STORE: {value: "filesystem"}
  LIVY_LIVY_SERVER_RECOVERY_STATE0STORE_URL: {value: "file:///data/livyStateStore"}
  LIVY_LIVY_RSC_JARS: {value: 'local\:///opt/livy/rsc-jars/livy-thriftserver-session-0.8.0-incubating-SNAPSHOT.jar,local\:///opt/livy/rsc-jars/netty-all-4.1.47.Final.jar,local\:///opt/livy/rsc-jars/asm-5.0.4.jar,local\:///opt/livy/rsc-jars/reflectasm-1.11.3.jar,local\:///opt/livy/rsc-jars/minlog-1.3.0.jar,local\:///opt/livy/rsc-jars/livy-rsc-0.8.0-incubating-SNAPSHOT.jar,local\:///opt/livy/rsc-jars/objenesis-2.5.1.jar,local\:///opt/livy/rsc-jars/livy-api-0.8.0-incubating-SNAPSHOT.jar'}
  LIVY_LIVY_REPL_JARS: {value: 'local\:///opt/livy/repl_2.12-jars/commons-codec-1.9.jar,local\:///opt/livy/repl_2.12-jars/livy-core_2.12-0.8.0-incubating-SNAPSHOT.jar,local\:///opt/livy/repl_2.12-jars/livy-repl_2.12-0.8.0-incubating-SNAPSHOT.jar'}
  LIVY_LIVY_FILE_LOCAL0DIR0WHITELIST: {value: "/opt/spark/python/lib"}
  LIVY_LIVY_REPL_ENABLE0HIVE0CONTEXT: {value: "false"}
  LIVY_SPARK_KUBERNETES_CONTAINER_IMAGE: {value: "harbor.datamodel.jiutian.hq.cmcc:8089/spark/livy-spark:0.8.0-incubating-spark_3.1.1_2.12-hadoop_3.2.0_cloud_TT7"}
  LIVY_SPARK_KUBERNETES_CONTAINER_IMAGE_PULL1POLICY: {value: "IfNotPresent"}
  LIVY_SPARK_EVENT1LOG_ENABLED: {value: "true"}
  LIVY_SPARK_EVENT1LOG_DIR: {value: "file:///data/eventLog"}
  LIVY_SPARK_KUBERNETES_DRIVER_ANNOTATION_CREATED0BY: {value: "livy"}
  LIVY_SPARK_KUBERNETES_EXECUTOR_ANNOTATION_CREATED0BY: {value: "livy"}
  LIVY_SPARK_KUBERNETES_DRIVER_LABEL_NAME: {value: "driver"}
  LIVY_SPARK_KUBERNETES_EXECUTOR_LABEL_NAME: {value: "executor"}
  #LIVY_SPARK_KUBERNETES_DRIVER_VOLUMES_PERSISTENT1VOLUME1CLAIM_DATA_OPTIONS_CLAIM1NAME: {value: "glusterfs-spark-pvc"}
  #LIVY_SPARK_KUBERNETES_DRIVER_VOLUMES_PERSISTENT1VOLUME1CLAIM_DATA_MOUNT_PATH: {value: "/data/k8sUpload"}
  #LIVY_SPARK_KUBERNETES_EXECUTOR_VOLUMES_PERSISTENT1VOLUME1CLAIM_DATA_OPTIONS_CLAIM1NAME: {value: "glusterfs-spark-pvc"}
  #LIVY_SPARK_KUBERNETES_EXECUTOR_VOLUMES_PERSISTENT1VOLUME1CLAIM_DATA_MOUNT_PATH: {value: "/data/k8sUpload"}
  LIVY_SPARK_SUBMIT_PY1FILES: {value: "local:///opt/spark/python/lib/pyspark.zip,local:///opt/spark/python/lib/py4j-0.10.9-src.zip"}
  LIVY_SPARK_KUBERNETES_FILE_UPLOAD_PATH: {value: "/data/k8sUpload"}
  # LIVY_SPARK_KUBERNETES_CONTAINER_IMAGE_PULL1SECRETS: {value: ""}
  # LIVY_LIVY_UI_HISTORY1SERVER1URL: {value: "https://cluster.example.com/history-server"} # to build links on Livy UI properly
  #
  # Spark UI proxy configs
  # LIVY_LIVY_SERVER_KUBERNETES_INGRESS_CREATE: {value: "false"}
  # LIVY_LIVY_SERVER_KUBERNETES_INGRESS_HOST: {value: "cluster.example.com"}
  #
  # Authentication configs for Spark UI proxy
  # External auth with OAuth2
  # LIVY_LIVY_SERVER_KUBERNETES_INGRESS_ADDITIONAL1ANNOTATIONS: {value: "kubernetes.io/tls-acme=true;nginx.ingress.kubernetes.io/auth-url=https://$host/oauth2/auth;nginx.ingress.kubernetes.io/auth-signin=https://$host/oauth2/start?rd=$escaped_request_uri"}
  # Basic auth
  # LIVY_LIVY_SERVER_KUBERNETES_INGRESS_ADDITIONAL1ANNOTATIONS: {value: "kubernetes.io/tls-acme=true;nginx.ingress.kubernetes.io/auth-type=basic;nginx.ingress.kubernetes.io/auth-secret=secret-namespace/auth-secret;nginx.ingress.kubernetes.io/auth-realm=Authentication Required"}
  #
  # HTTPS for Spark UI proxy
  # LIVY_LIVY_SERVER_KUBERNETES_INGRESS_PROTOCOL: {value: "https"}
  # LIVY_LIVY_SERVER_KUBERNETES_INGRESS_TLS_SECRET1NAME: {value: "spark-cluster-tls"}
  #
  # Additional Nginx Ingress configs for Spark UI proxy
  # LIVY_LIVY_SERVER_KUBERNETES_INGRESS_ADDITIONAL1CONF1SNIPPET: {value: ""}
  #
  # LIVY_ENV_VAR_FROM_CONFIG_MAP:
  #   valueFrom:
  #     configMapKeyRef:
  #       name: myconfig
  #       key: config.key
  # LIVY_ENV_VAR_FROM_SECRET:
  #   valueFrom:
  #     secretKeyRef:
  #       name: mysecret
  #       key: secret.key

envFrom: []
# - configMapRef:
#     name: env-configmap
# - secretRef:
#     name: env-secrets

livyConf: {}
#  fromConfigMap: "livy-conf-config-map"
#  fromSecret: "livy-conf-secret"

sparkDefaultsConf: {}
# fromConfigMap: "spark-defaults-conf-map"
# fromSecret: "spark-defaults-conf-secret"

livyClientConf: {}
# fromConfigMap: "livy-client-conf-config-map"
# fromSecret: "livy-client-conf-secret"
